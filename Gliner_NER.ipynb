{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebef498c-d889-46e6-a605-a0f90a91a99e",
   "metadata": {},
   "source": [
    "## Install all libraries\n",
    "- Spacy\n",
    "- GLiNER\n",
    "- Download the trained model for English en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa93d5-a53b-43b8-9ec6-5c0225e0ee49",
   "metadata": {},
   "source": [
    "- Author: Alva Rani James, PHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9aa3e-aa61-4419-8cde-5ad672caa8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U spacy \n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install gliner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5c031-d532-4286-8eef-ce22dfa16090",
   "metadata": {},
   "source": [
    "## import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594d3efb-9d59-448a-ad9a-248d7bea1c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajames\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "# import the base gliner model\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc92ab3-c39f-4ae7-a42d-e9e28dbd1cb5",
   "metadata": {},
   "source": [
    "## Define the text for the NER task and get the number of words within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d71fb3-121c-4379-8525-6ea518bad2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in the text: 730\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Nutrition labs at the next visit\n",
    "Follow nutrition recommendations.\n",
    "Encouraged intake of 3 meals per day of low protein foods.\n",
    "Encouraged intake of water instead of calorie drinks.\n",
    "Aim for <15gm per day of protein from diet\n",
    "Discussed importance of daily diet log to aid with protein counting and weight loss\n",
    "Begin vitamin D supplementation, 1000 IUs per day \n",
    "We will contact the PCPs office and request assistance in placing referral to a local therapist/psychologist\n",
    "We will continue to work on obtaining insurance coverage for her formula. \n",
    "If this continues to be deferred, we will consider starting tyrosine supplementation in the interim.\n",
    "Followup in the metabolic clinic in 1 months  \n",
    "\"\"\"\n",
    "print(\"The number of words in the text:\",len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139608ad-f58a-409d-9345-18a1ea966db0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 1: GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53ffd2b7-8d0d-4249-93c9-cf8b3e9711f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water => breast milk\n",
      "calorie drinks => formula\n",
      "vitamin D => supplementation\n",
      "formula => formula\n",
      "tyrosine supplementation => supplementation\n"
     ]
    }
   ],
   "source": [
    "# define the labels\n",
    "labels = ['breast milk','protein', 'supplementation'\n",
    "    'liquid predominant diet',\n",
    "    'formula', \n",
    "    'supplementation',\n",
    "    'meals',\n",
    "    'water']\n",
    "entities = model.predict_entities(text, labels, threshold=0.5)\n",
    "for entity in entities: print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52e125-4dab-4f3d-9cbb-e6c79816fbbb",
   "metadata": {},
   "source": [
    "#### If you change the threshold\n",
    "- Between 0.5 to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f288261e-bb81-41a4-8a89-1a56dc8a6005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the threshold: 0.5 water => breast milk\n",
      "for the threshold: 0.5 calorie drinks => formula\n",
      "for the threshold: 0.5 vitamin D => supplementation\n",
      "for the threshold: 0.5 formula => formula\n",
      "for the threshold: 0.5 tyrosine supplementation => supplementation\n",
      "for the threshold: 0.8 water => water\n",
      "for the threshold: 0.8 vitamin D supplementation => supplementation\n",
      "for the threshold: 0.8 tyrosine supplementation => supplementation\n",
      "for the threshold: 0.9 water => water\n"
     ]
    }
   ],
   "source": [
    "thres =[0.5,0.8,0.9]\n",
    "for thre in thres:\n",
    "    entities = model.predict_entities(text, labels, threshold=thre)\n",
    "    for entity in entities: \n",
    "        print(\"for the threshold:\",thre, entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61ef248-bd27-4d96-8a01-899e01511520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.77 ns ± 0.201 ns per loop (mean ± std. dev. of 7 runs, 100,000,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 7.77 ns ± 0.201 ns per loop (mean ± std. dev. of 7 runs, 100,000,000 loops each)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit -o 1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45da9e49-799e-4c30-b622-3b30daea1120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.643843499994546"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oct(x):\n",
    "   return x*x\n",
    "timeit.Timer(\"for x in range(100): oct(x)\", \"gc.enable()\").timeit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e07039-d19e-4665-8f1b-253044a0cd08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 2: Example with spacy\n",
    "- Customized labels using Pharsematcher function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d016c072-5496-47b3-8d61-c0eed02449af",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIET => meals\n",
      "DIET => protein\n",
      "DIET => water\n",
      "DIET => protein\n",
      "DIET => protein\n",
      "DIET => supplementation\n",
      "DIET => formula\n",
      "DIET => supplementation\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)\n",
    "food_list = [nlp.make_doc(text) for text in [\n",
    "  'breast milk','protein', 'supplementation',\n",
    "    'liquid predominant diet',\n",
    "    'formula', \n",
    "    'supplementation',\n",
    "    'meals',\n",
    "    'water']]\n",
    "\n",
    "phrase_matcher.add(\"DIET\",None, *food_list)\n",
    "doc    = nlp(text)\n",
    "matches = phrase_matcher(doc)\n",
    "\n",
    "# Assign labels and update Doc object with entities\n",
    "for match_id, start, end in matches:\n",
    "    rule_id = nlp.vocab.strings[match_id]  # get the label\n",
    "    span = doc[start : end]  # get the matched slice of the doc\n",
    "    print(rule_id,\"=>\", span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086dae1e-ff24-4ba3-9c08-9c63c981718e",
   "metadata": {},
   "source": [
    "## Get the time for SPACY and GLiNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bc0b8-7117-4aaa-a129-d788415ce197",
   "metadata": {},
   "source": [
    "- GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bf1a2cc-95c6-4353-bb2e-4b05b11cbcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water => breast milk\n",
      "calorie drinks => formula\n",
      "vitamin D => supplementation\n",
      "formula => formula\n",
      "tyrosine supplementation => supplementation\n",
      "Time taken for GLiNER: 0.00013079999916953966 seconds\n"
     ]
    }
   ],
   "source": [
    "code_to_measure = '''\n",
    "for entity in entities: print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "'''\n",
    "time_taken = timeit.timeit(stmt=code_to_measure, globals=globals(), number=1)\n",
    "print(\"Time taken for GLiNER:\", time_taken, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed3a43-f744-4729-a7eb-c44281395eb4",
   "metadata": {},
   "source": [
    "- SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceec68ba-ba2d-4f1e-a62b-2e2817b40530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIET => meals\n",
      "DIET => protein\n",
      "DIET => water\n",
      "DIET => protein\n",
      "DIET => protein\n",
      "DIET => supplementation\n",
      "DIET => formula\n",
      "DIET => supplementation\n",
      "Time taken for SPACY: 0.0003290999957243912 seconds\n"
     ]
    }
   ],
   "source": [
    "code_to_measure= '''\n",
    "for match_id, start, end in matches:\n",
    "    rule_id = nlp.vocab.strings[match_id]  # get the label\n",
    "    span = doc[start : end]  # get the matched slice of the doc\n",
    "    print(rule_id,\"=>\", span.text)\n",
    "'''\n",
    "time_taken = timeit.timeit(stmt=code_to_measure, globals=globals(), number=1)\n",
    "print(\"Time taken for SPACY:\", time_taken, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
